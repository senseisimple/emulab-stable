		Application Centric Internet Modelling - UDP
		--------------------------------------------

Node Setup:
-----------

Application is run on the Emulab nodes, and it is LD_PRELOADed with
libnetmon.

libnetmon on each Emulab node talks to application monitor using 
a Unix domain socket and sends information about the sendto() 
(and datagram connect() ) calls (intervals between sendto calls, as well as size
of data sent by each call ) made by the application on that node.

The application monitor sends this information to the corresponding management
agent running on a planetlab node.


How does it Work ? 
------------------

Eg: Let 'nodeA' and 'nodeB' be the hosts running the management agent on planetlab.
Let us assume that the UDP data transfer is one directional, from nodeA -> nodeB.

As of now, the management agent is programmed to send UDP traffic just as it was
sent by the application running in Emulab - No effort is made to control the rate
at which UDP packets are sent and no congestion control is used. For practical
reasons, to play nice with TCP and other traffic in the network between planet lab
nodes, some form of congestion control would probably be introduced in the
management agent in the future.

The management agent on nodeA sends UDP packets to nodeB. We intend to
replicate the sendto() calls being done by the application in Emulab, observe
the throughput and RTT achieved by these packets and feed those parameters
back to the monitor. The application in Emulab is not affected by the exact contents 
of the data being sent between the planetlab nodes.


So, we use a simple application level protocol between the management agents.
This protocol is implemented using the application level data of the UDP packets.

Protocol in the data packets:
-----------------------------
nodeA sends UDP packets to nodeB, embedding monotonically increasing sequence numbers
in the packets. 

Whenever nodeA sends a packet to nodeB, it captures the timestamp when the packet is
about to be put on the network. On receiving an acknowledgement from nodeB, again a 
timestamp is taken at the time of arrival of the acknowledgement. Half of the difference
between these two timestamps for a packet gives an approximate value of the RTT
for that packet - Or the one way delay.

Acknowledgements ( & redundancy ):
---------------------------------
nodeB echoes the packets back, indicating that the particular
sequence number packet was correctly received.

In each ACK packet, nodeB includes the sequence number of the packet
being acknowledged, as well as the sequence numbers of the last 3 packets
it has received. Including these extra sequence numbers in each ACK makes
the throughput calculations resilient to the loss of a small number of
( 3 consecutive ACK packets can be dropped without any effect on the
throughput calculation ) ACK packets on the reverse path.

The ACK packets also contain the timestamps at the receiver when the original
packets were received. The timestamp for the packet being ACKed is an
absolute value ( in micro seconds ), and the values for redundant ACKs are
relative to this absolute value.

As of now, the acknowledgement packets are of the same size as the received
data packets. If they are a fixed minimum size, then it could affect the RTT
calculations. If the packets sent from nodeA -> nodeB are say 1500 bytes long
and the ACK packets are about 50 bytes, then the transmission delay on the forward
path is going to be more than the transmission delay on the reverse path.

When one way delay is calculated as half of RTT, this causes the one way delay
estimate to be lower the actual value for the forward path ( if the ACKs are a fixed minimum size).


Minimum Delay:
-------------

The minimum of these one way delays is taken as having no queuing delay and hence
is considered as the sum of ( propagation + transmission + processing ) delays
in the forward path. Whenever the minimum delay value changes, an event message is
sent to the application monitor with the new value - and the dummy net pipe
corresponding to the connection between nodeA and nodeB is updated with that delay value
for the delay queue.


Dummy net Queue Size:
---------------------

We also keep track of the maximum one way delay. The difference between the maximum one
way delay and the minimum from above, gives the value of approximate maximum queuing delay
on the forward path. Whenever there is a new maximum queuing delay value, an event is sent to the
application monitor and the value is used to set the maximum queue size for the dummy net pipe.

Note: UDP packets sent by from nodeA may not always be the maximum sized packets, as is most
often the case with TCP. So, the minimum and maximum delay values need to be calculated ( ideally for
every packet size), keeping the maximum sized UDP packet in mind. The one way delay values are
thus scaled to represent maximum sized packets. ( we divide the one way delay by number of bytes in
the packet + overhead, and then multiply it by 1500 ).

Throughput: 
-----------

Throughput = (size of data being ACKed) / ( last_receiver_time_stamp - current_receiver_time_stamp )

Here, throughput is being calculated depending on when each packet was seen by the receiver. The
assumption is that there is a single bottleneck link in the network: and the packets seen
by the receiver will be spaced ( in time ) depending on the queueing & transmission delays
encountered by the packets at the bottleneck.

We assume that the forward and reverse paths are symmetric, in terms of the path
capacity and delay introduced - although this might not be true in some cases.

However, the spacing between the packets at the receiver need not be the same as that 
at the bottleneck.This spacing can become compressed(similar to TCP ACK compression) later on in 
the network ( at a fast link for example ),and it is possible for the packets to arrive 
immedietly after one another at the receiver.

The delays seen between the receiver in this case will be different than the spacing between
the packets after the bottleneck link and we will end up overestimating the throughput value.

The reason for this is that we fail to take queuing delay into account for closely spaced
packets arriving at the receiver. Since the clocks are not synchronized between the sender and
receiver, it is not possible to accurately calculate the one way delay at the receiver.

This compression of packets can affect the throughput calculated - currently we do not of
any way to avoid this potential problem. ( it does seem to occur infrequently, only on a few paths ).


Problems that might crop up:
----------------------------

1) We are using libpcap in the management agent on planet lab nodes. Due to
long delays in scheduling of the application ( & the limited BPF buffer size), 
this might result in some UDP packets being dropped by libpcap.

The alternative is to use SO_TIMESTAMP option provided for datagram sockets.
These timestamps are also as accurate as libpcap timestamps and are provided
for each received UDP packet by the socket layer. If this option is used,
then we can do away with libpcap.

However, SO_TIMESTAMP option implies that we are dependent on the UDP receive
socket buffer not getting full, while we are on planet lab ready queue.
If this buffer is full and packets are dropped by the kernel, then the application
simply does not know about the dropped packets.

Since libpcap allows us to capture only part of each packet ( we plan to capture only
the first 128 bytes ), its buffer can hold a larger number of packets than UDP
receive buffer can ( assuming MTU sized UDP packets ), and hence should be less
affected by the packet drop problem.

This is just a hypothesis and needs to be tested on planetlab.


2) Reordering of packets on the forward path & reordering of ACKs on the reverse path

We currently ignore the reordering of packets/ACKs on forward/reverse paths.

If this happens persistently and is perceived as a characteristic of some links,
then it might need to be addressed.





